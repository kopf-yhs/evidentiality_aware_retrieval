{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import re\n",
    "import random\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "random.seed(0)\n",
    "\n",
    "make_random_mask = False\n",
    "exact_answers = []\n",
    "not_include_answer = []\n",
    "span_len = 16\n",
    "WINDOWING=False\n",
    "\n",
    "def web_parse(text):\n",
    "    soup = BeautifulSoup(text)\n",
    "    text = soup.get_text()\n",
    "    return text\n",
    "\n",
    "def find_random_idx(ans_start_tok, answer_end_tok,txt):\n",
    "\n",
    "    max_bound = max(len(re.split(' ',txt))-(answer_end_tok-ans_start_tok), answer_end_tok)\n",
    "    middle_bound = max(ans_start_tok-(answer_end_tok-ans_start_tok),0)\n",
    "\n",
    "    rand_candidates = list(range(middle_bound))+list(range(answer_end_tok,max_bound))\n",
    "\n",
    "    rand_start_idx = random.choice(rand_candidates)\n",
    "    rand_end_idx = rand_start_idx + (answer_end_tok-ans_start_tok)\n",
    "    return rand_start_idx, rand_end_idx\n",
    "\n",
    "masked_spans=[]\n",
    "\n",
    "def find_and_mask(answers, txt):\n",
    "    masked_txt = txt\n",
    "    masked=False\n",
    "    for ans in answers:\n",
    "        ans_len_char = len(ans)\n",
    "        ans = re.sub(r'([^a-zA-Z0-9,\\.!\\? -])',r'\\\\\\1',ans)\n",
    "\n",
    "        ans_split = ans.split(' ')\n",
    "        ans_len_token = len(ans_split)\n",
    "\n",
    "        re_ans = '( )?'.join(ans_split)\n",
    "        re_ans = re.compile(re_ans,re.I)\n",
    "        start_idxs = list(re.finditer(re_ans, masked_txt))\n",
    "        ans_spans = [(-1,0)] + [(start_idx.start(), start_idx.start() + ans_len_char) for start_idx in start_idxs] + [(len(masked_txt),-1)]\n",
    "\n",
    "        if len(start_idxs) > 0:\n",
    "            new_masked_txt = ''\n",
    "            for i, _ in enumerate(ans_spans[:-1]):\n",
    "                s_idx = ans_spans[i][1]\n",
    "                e_idx = ans_spans[i+1][0]\n",
    "                new_masked_txt += masked_txt[s_idx:e_idx]+' '\n",
    "            masked_txt = new_masked_txt\n",
    "            masked=True\n",
    "\n",
    "    if masked:\n",
    "        return masked_txt\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x7f894fbe8780>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "#nlp.remove_pipe('sentencizer')\n",
    "config = {\n",
    "    'punct_chars':[\n",
    "        '!', '.', '?', '։', '؟', '۔', '܀', '܁', '܂', '߹',\n",
    "        '।', '॥', '၊', '။', '።', '፧', '፨', '᙮', '᜵', '᜶', '᠃', '᠉', '᥄',\n",
    "        '᥅', '᪨', '᪩', '᪪', '᪫', '᭚', '᭛', '᭞', '᭟', '᰻', '᰼', '᱾', '᱿',\n",
    "            '‼', '‽', '⁇', '⁈', '⁉', '⸮', '⸼', '꓿', '꘎', '꘏', '꛳', '꛷', '꡶',\n",
    "            '꡷', '꣎', '꣏', '꤯', '꧈', '꧉', '꩝', '꩞', '꩟', '꫰', '꫱', '꯫', '﹒',\n",
    "            '﹖', '﹗', '！', '．', '？', '𐩖', '𐩗', '𑁇', '𑁈', '𑂾', '𑂿', '𑃀',\n",
    "            '𑃁', '𑅁', '𑅂', '𑅃', '𑇅', '𑇆', '𑇍', '𑇞', '𑇟', '𑈸', '𑈹', '𑈻', '𑈼',\n",
    "            '𑊩', '𑑋', '𑑌', '𑗂', '𑗃', '𑗉', '𑗊', '𑗋', '𑗌', '𑗍', '𑗎', '𑗏', '𑗐',\n",
    "            '𑗑', '𑗒', '𑗓', '𑗔', '𑗕', '𑗖', '𑗗', '𑙁', '𑙂', '𑜼', '𑜽', '𑜾', '𑩂',\n",
    "            '𑩃', '𑪛', '𑪜', '𑱁', '𑱂', '𖩮', '𖩯', '𖫵', '𖬷', '𖬸', '𖭄', '𛲟', '𝪈',\n",
    "            '｡', '。',','\n",
    "    ],\n",
    "    'overwrite':True,\n",
    "}\n",
    "nlp.add_pipe('sentencizer',config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "class MyHTMLParser(HTMLParser):\n",
    "    #def init_texts(self):\n",
    "    #    self.texts=['']\n",
    "        \n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        print(\"Encountered a start tag:\", tag)\n",
    "        #self.texts.append('')\n",
    "\n",
    "    def handle_endtag(self, tag, attrs):\n",
    "        print(\"Encountered a end tag:\", tag)\n",
    "        #self.texts.append('')\n",
    "\n",
    "    #def handle_data(self, data):\n",
    "    #    self.texts[-1]+=data \n",
    "\n",
    "    #def get_texts(self):\n",
    "    #    return self.texts\n",
    "\n",
    "parser = MyHTMLParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NQ train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle, json\n",
    "\n",
    "t5_output_path = # glob expression of T5 output files\n",
    "\n",
    "all_results = list()\n",
    "for pp in Path('.').glob(t5_output_path):\n",
    "    with open(pp, 'rb') as f:\n",
    "        all_results.extend(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = # Train datasets in DPR format. See https://github.com/facebookresearch/DPR\n",
    "with open(train_data_path,'r') as f:\n",
    "    train_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_dict = dict()\n",
    "original_results_dict = dict()\n",
    "\n",
    "for entry in all_results:\n",
    "    ctx_id = entry[0]\n",
    "    question = entry[1]\n",
    "    ctx = entry[2]\n",
    "    sent_id = entry[3]\n",
    "    confidence_score = entry[4]\n",
    "\n",
    "    if sent_id >= 0:\n",
    "        if question not in all_results_dict:\n",
    "            all_results_dict[question] = list()\n",
    "        all_results_dict[question].append([question, ctx, sent_id, confidence_score])\n",
    "    else:\n",
    "        original_results_dict[question] = [question, ctx, sent_id, confidence_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/58880 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 33332/58880 [27:05<1:00:29,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encountered a start tag: ref\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 50449/58880 [32:36<06:48, 20.64it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encountered a start tag: refher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58880/58880 [34:48<00:00, 28.19it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "cf_data = list()\n",
    "spans_with_scores = list()\n",
    "\n",
    "for entry in tqdm(train_data):\n",
    "    question = entry['question']\n",
    "    positive_ctxs = entry['positive_ctxs']\n",
    "    answers = entry['answers']\n",
    "    cf_ctxs = list()\n",
    "    spans_per_que = {\n",
    "        'question' : question,\n",
    "        'ctx' : positive_ctxs[0],\n",
    "        'answers': answers \n",
    "    }\n",
    "\n",
    "    for ctx in positive_ctxs[:1]:\n",
    "        keep_sentences = list()\n",
    "        text = web_parse(ctx['text'])\n",
    "        sentences = nlp(text).sents\n",
    "        \n",
    "        #print([s.text for s in sentences])\n",
    "        targets=[]\n",
    "        target=[]\n",
    "        for s_id, sent in enumerate(sentences):\n",
    "            if len(sent)<=3: # consider more than three words as a sentence\n",
    "                target.extend([t.text for t in sent])\n",
    "                if len(target)>6:\n",
    "                    targets.append(' '.join([token for token in target]))\n",
    "                    target=[]\n",
    "                    continue\n",
    "            else:\n",
    "                targets.append(' '.join([token.text for token in sent]))\n",
    "                target=[]\n",
    "\n",
    "        evi_anno = all_results_dict[question]\n",
    "        evi_cands = sorted(evi_anno, key=lambda x : x[3], reverse=True)\n",
    "        top_conf_cand = evi_cands[0]\n",
    "        top_conf_cand_idx = top_conf_cand[2]\n",
    "        evi_cand_scores = np.array([ca[3] for ca in evi_cands])\n",
    "        softmax_evi_cand_scores = softmax(evi_cand_scores).tolist()\n",
    "        \n",
    "\n",
    "        try:\n",
    "            original_score = original_results_dict[question][3]\n",
    "        except IndexError:\n",
    "            print(original_results_dict[question])\n",
    "\n",
    "        cand_sents_list = list()\n",
    "        for cand, sm_score in zip(evi_cands, softmax_evi_cand_scores):\n",
    "            cand_sent_idx = cand[2]\n",
    "            if cand_sent_idx >= len(targets):\n",
    "                continue\n",
    "            cand_sent = targets[cand_sent_idx]\n",
    "            cand_score = cand[3]\n",
    "            cand_sents_list.append({\n",
    "                'span' : cand_sent,\n",
    "                'span_idx' : cand_sent_idx,\n",
    "                'score' : cand_score,\n",
    "                'softmax_score' : sm_score,\n",
    "                'score_diff' : (cand_score - original_score)/original_score * 100\n",
    "            })\n",
    "        spans_per_que['ctxs'] = cand_sents_list\n",
    "\n",
    "        try:\n",
    "            keep_sentences = targets[:top_conf_cand_idx] + targets[top_conf_cand_idx+1:]\n",
    "        except:\n",
    "            print(question)\n",
    "            print(ctx)\n",
    "            print(top_conf_cand)\n",
    "\n",
    "        masked_text = ' '.join(keep_sentences)\n",
    "        parser.feed(masked_text)\n",
    "\n",
    "        title = ctx['title']\n",
    "        if find_and_mask(answers, title):\n",
    "            title = find_and_mask(answers, title)\n",
    "        \n",
    "        cf_ctx = copy.deepcopy(ctx)\n",
    "        cf_ctx['title'] = title\n",
    "        cf_ctx['text'] = masked_text\n",
    "        cf_ctxs.append(cf_ctx)\n",
    "    \n",
    "    entry['cf_negative_ctxs'] = cf_ctxs\n",
    "    cf_data.append(entry)\n",
    "    spans_with_scores.append(spans_per_que)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_train_data_path = '' # output train file in DPR format.\n",
    "with open(train_data_path,'w') as f:\n",
    "    json.dump(cf_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "evidence_annotation_path = '' # json files with evidence annotation for case analysis\n",
    "with open(evidence_annotation_path,'w') as f:\n",
    "    json.dump(spans_with_scores, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dh_dpr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
